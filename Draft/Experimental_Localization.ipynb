{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting Localization with SIFT Matching and Essential Matrix\n",
    "\n",
    "This script takes 3 images from the training dataset, attempting to use the first 2 images to predict the other one's location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "* Set input image filenames to variables `i1`,`i2`\n",
    "* Set validation image filename to variable `i3`\n",
    "* Run onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = 'IMG3200_1'\n",
    "i2 = 'IMG3640_2'\n",
    "i3 = 'IMG3001_1'\n",
    "\n",
    "img = cv2.imread('./train/' + i1 + '.jpg')\n",
    "img2 = cv2.imread('./train/' + i2 + '.jpg')\n",
    "img3 = cv2.imread('./train/' + i3 + '.jpg')\n",
    "\n",
    "# SIFT keypoints\n",
    "sift = cv2.SIFT_create()\n",
    "kp,des = sift.detectAndCompute(img,None)\n",
    "kp2,des2 = sift.detectAndCompute(img2,None)\n",
    "kp3,des3 = sift.detectAndCompute(img3,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLANN matcher\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "# Limit for Lowe's Ratio test\n",
    "ratio = 0.6\n",
    "# 8 points are needed for 8-point algorithm\n",
    "MIN_MATCH_NUM = 8\n",
    "\n",
    "# Matching for each pair of image\n",
    "matches = flann.knnMatch(des,des2,k=2)\n",
    "good = [m for m,n in matches if m.distance < ratio*n.distance]\n",
    "if len(good)> MIN_MATCH_NUM:\n",
    "    pts12 = np.float32([kp[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    pts21 = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "matches = flann.knnMatch(des,des3,k=2)\n",
    "good = [m for m,n in matches if m.distance < ratio*n.distance]\n",
    "if len(good)> MIN_MATCH_NUM:\n",
    "    pts13 = np.float32([kp[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    pts31 = np.float32([kp3[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "matches = flann.knnMatch(des2,des3,k=2)\n",
    "good = [m for m,n in matches if m.distance < ratio*n.distance]\n",
    "if len(good)> MIN_MATCH_NUM:\n",
    "    pts23 = np.float32([kp2[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    pts32 = np.float32([kp3[m.trainIdx].pt for m in good]).reshape(-1,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic Camera Matrix\n",
    "FOV_X = 73.3*np.pi/180\n",
    "FOV_Y = 53.1*np.pi/180\n",
    "\n",
    "cx = img.shape[1]/2\n",
    "cy = img.shape[0]/2\n",
    "\n",
    "fx = cx/np.tan(FOV_X/2)\n",
    "fy = cy/np.tan(FOV_Y/2)\n",
    "\n",
    "K = np.array([[fy,0,cy],\n",
    "              [0,fx,cx],\n",
    "              [0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the respective rotation and translation\n",
    "E,_ = cv2.findEssentialMat(pts12,pts21,K,method=cv2.FM_LMEDS)\n",
    "_,R,T,_ = cv2.recoverPose(E,pts12,pts21,K)\n",
    "\n",
    "E1,_ = cv2.findEssentialMat(pts13,pts31,K,method=cv2.FM_LMEDS)\n",
    "_,R1,T1,_ = cv2.recoverPose(E1,pts13,pts31,K)\n",
    "\n",
    "E2,_ = cv2.findEssentialMat(pts23,pts32,K,method=cv2.FM_LMEDS)\n",
    "_,R2,T2,_ = cv2.recoverPose(E2,pts23,pts32,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 46.31932192 -53.81728035]] [[ 49.01932192 -57.01728035]] [[ 50.51932192 -56.81728035]]\n",
      "[[-2.7  3.2]]\n"
     ]
    }
   ],
   "source": [
    "# Print out coordinates to know what to expect\n",
    "train_xy = pd.read_csv('train.csv')\n",
    "pt1 = train_xy.loc[train_xy['id']==i1,['x','y']].values\n",
    "pt2 = train_xy.loc[train_xy['id']==i2,['x','y']].values\n",
    "pt3 = train_xy.loc[train_xy['id']==i3,['x','y']].values\n",
    "print(pt1,pt2,pt3)\n",
    "print(pt1-pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displacement Vector\n",
    "dp = (pt1-pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix_from_vectors(vec1, vec2):\n",
    "    \"\"\" Find the rotation matrix that aligns vec1 to vec2\n",
    "    \n",
    "    Params\n",
    "    ---\n",
    "    - vec1: A 3d \"source\" vector\n",
    "    - vec2: A 3d \"destination\" vector\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    mat: A transform matrix which when applied to vec1, aligns it with vec2.\n",
    "    \"\"\"\n",
    "    a = (vec1 / np.linalg.norm(vec1)).reshape(3)\n",
    "    b = (vec2 / np.linalg.norm(vec2)).reshape(3)\n",
    "    v = np.cross(a, b)\n",
    "    c = np.dot(a, b)\n",
    "    s = np.linalg.norm(v)\n",
    "    kmat = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])\n",
    "    rotation_matrix = np.eye(3) + kmat + kmat.dot(kmat) * ((1 - c) / (s ** 2))\n",
    "    return rotation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.44870939e-01],\n",
       "       [ 2.25363370e-16],\n",
       "       [ 7.64291484e-01]])"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm correct mapping, by ensuring that rotation product is same scale as displacement vector\n",
    "r3d = rotation_matrix_from_vectors(T, np.insert(dp,[1],0))\n",
    "r3d @ T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83449008],\n",
       "       [ 0.17053015],\n",
       "       [ 0.52397115]])"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displacement unit vector from Image 1 to Image 3, real world coordinates\n",
    "V1 = r3d @ T1\n",
    "V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.78825975],\n",
       "       [ 0.6072432 ],\n",
       "       [-0.09951014]])"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displacement unit vector from Image 2 to Image 3, real world coordinates\n",
    "V2 = r3d @ (R @ T2)\n",
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that unit vectors in real world are found, proceed to solve equation\n",
    "unit_vectors = np.append(V1[[0,2]],-V2[[0,2]], axis=1)\n",
    "# Solve this matrix and get b: V[b,c]' = D\n",
    "const = np.linalg.solve(unit_vectors,dp.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking correctness of result, by trying to add up the vector from both images and ensure they produce the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 51.01457279, -56.76539929]])"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt1 - const[0,0] * V1[[0,2]].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 51.01457279, -56.76539929]])"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt2 - const[1,0] * V2[[0,2]].flatten()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4621005da5c26ac209901ca167bf25025457b064ec855aea9ba97365ac8d4984"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
